hydra:
  job:
    chdir: false
defaults:
  - model_config: hf-gen_a      # the model config of the LM inferencer, can be `hf-gen_a` or `api-gen-a`

# model_name: '/new_disk/models_for_all/llama-2-7b-chat-hf'                # the model name of the LM inferencer
model_name: ???                # the model name of the LM inferencer
task_name: ???
output_file: ???                # predictions will be saved to `output_file`
pretrained_model: ???
log_path: ???

batch_size: 1                  # the batch_size of the model when using `hf-gen_a` model_config; for api models, the batch size is decided based on the number of openai keys.


# for simple inference
base_dataset_reader:
  _target_: src.dataset_readers.base_dsr1.BaseDatasetReader
  task_name: ${task_name}
  model_name: ${model_name}
  field: gen_a
  ds_size: null                # number of instances used for the dataset, 'null' refers to 'all'
  dataset_path: null          # one of `dataset_path` and `dataset_split` must be set
